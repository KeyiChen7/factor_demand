{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "- This notebook intends to walk through the steps of replicating Table 2.\n",
    "- `df_combo` is the main sample as shown in Table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wrds\n",
    "\n",
    "from load_CRSP_fund import load_CRSP_combined_file\n",
    "from load_mflink import load_mflink1\n",
    "\n",
    "import config\n",
    "OUTPUT_DIR = Path(config.OUTPUT_DIR)\n",
    "path = Path(OUTPUT_DIR) / \"main_sample.parquet\" \n",
    "df_combo = pd.read_parquet(path)\n",
    "\n",
    "df_crsp = load_CRSP_combined_file()\n",
    "df_mflink1 = load_mflink1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRSP Mutual Fund Data\n",
    "\n",
    "- CRSP data and mflink1 are merged based on `crsp_fundno`to obtain the appropriate `wficn`.\n",
    "- Calculate `mret` and `mtna` for each `wficn`.\n",
    "- The new CRSP data is then merged with `df_combo` by `year` and `wficn` to get the main sample's monthly returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crsp = df_crsp.merge(df_mflink1, how=\"inner\", on=\"crsp_fundno\").reset_index(drop=True)\n",
    "\n",
    "df_crsp = df_crsp.sort_values([\"caldt\", \"wficn\"])\n",
    "df_crsp['mret'] = df_crsp['mret'].fillna(0)\n",
    "df_crsp['lipper_class_name'] = df_crsp['lipper_class_name'].fillna('None')\n",
    "\n",
    "df_crsp = df_crsp[~df_crsp['lipper_class_name'].astype(str).str.contains('International|Fixed Income|Precious Metal', case=False, regex=True)]\n",
    "ret = df_crsp.groupby([\"caldt\", \"wficn\", 'lipper_class_name'])[\"mret\"].mean().reset_index().rename(columns={\"mret\": \"crsp_ret\"})\n",
    "tna = df_crsp.groupby([\"caldt\", \"wficn\", 'lipper_class_name'])[\"mtna\"].sum().reset_index().rename(columns={\"mtna\": \"crsp_tna\"})\n",
    "df_crsp = pd.merge(pd.merge(ret, tna, on=[\"caldt\", \"wficn\", 'lipper_class_name'], how=\"inner\"), \n",
    "                   df_crsp[[\"caldt\", \"wficn\", 'lipper_class_name', 'index_fund_flag']], on=[\"caldt\", \"wficn\", 'lipper_class_name'], how=\"inner\").sort_values([\"caldt\", \"wficn\"])\n",
    "df_crsp = df_crsp.drop_duplicates()\n",
    "df_crsp = df_crsp.rename(columns={\"caldt\": \"date\"})\n",
    "\n",
    "df_crsp['year'] = df_crsp['date'].dt.year.astype('int')\n",
    "df_crsp = pd.merge(df_crsp, df_combo[['year', 'wficn']], on=[\"year\", \"wficn\"], how=\"inner\")\n",
    "\n",
    "df_crsp['date'] = df_crsp['date'].dt.strftime('%Y%m').astype('int')\n",
    "df_crsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "float_format_func = lambda x: '{:.2f}'.format(x)\n",
    "df_crsp = df_crsp.rename(columns={'lipper_class_name': 'lipper class','crsp_ret': '$crsp_{ret}$', 'crsp_tna':'$crsp_{TNA}$', 'index_fund_flag':'index fund flag'}) \n",
    "\n",
    "latexTS_crsp_t2 = df_crsp.tail(10).to_latex(float_format = float_format_func)\n",
    "\n",
    "path_to_save = f'../output/table_crsp_t2.tex'\n",
    "\n",
    "with open(path_to_save, 'w') as f: \n",
    "    f.write(latexTS_crsp_t2)\n",
    "    \n",
    "df_crsp = df_crsp.rename(columns={'lipper class name':'lipper_class_name','$crsp_{ret}$': 'crsp_ret', '$crsp_{TNA}$':'crsp_tna', 'index fund flag':'index_fund_flag'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fama French Factors\n",
    "\n",
    "- Factor returns, `df_ff`, are pulled from Kenneth R. French's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ff = pd.read_csv(Path(config.DATA_DIR)/'manual'/'F-F_Research_Data_5_Factors_2x3.csv').drop(['RF'], axis=1)\n",
    "df_mom = pd.read_csv(Path(config.DATA_DIR)/'manual'/'F-F_Momentum_Factor.csv')\n",
    "df_ff = df_ff.merge(df_mom, how='inner', on=['date'])\n",
    "df_ff = df_ff[(df_ff['date'] >= 198001) & (df_ff['date'] <= 201912)]\n",
    "df_ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CRSP data and factor returns are merged, and for each fund i in month t, flow_{i,t} is calculated using the formula:\n",
    "\n",
    "$$\n",
    "\\text{flow}_{i,t} = \\frac{\\text{TNA}_{i,t}}{\\text{TNA}_{i,t-1}} \\times (1 + \\text{ret}_{i,t})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_crsp[df_crsp['date'] <= 201912], df_ff, on=['date'], how=\"outer\").sort_values([\"date\"])\n",
    "flow = df_reg.groupby('wficn').apply(lambda d: d['crsp_tna']/(d['crsp_tna'].shift(1)) - (1+d['crsp_ret'])).reset_index().rename(columns={'level_1': 'index', 0: \"flow\"})\n",
    "flow.set_index('index', inplace=True)\n",
    "df_reg = pd.merge(df_reg, flow[['flow']], left_index=True, right_index=True).sort_values(['wficn', 'date'])\n",
    "df_reg[['crsp_ret', 'flow']] *= 100\n",
    "df_reg.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_reg= df_reg.fillna(0)\n",
    "df_reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " latexTS_df_reg = df_reg.tail(10).to_latex(float_format = float_format_func)\n",
    "\n",
    "path_to_save = f'../output/table_fama_french_t2.tex'\n",
    "\n",
    "with open(path_to_save, 'w') as f: \n",
    "    f.write(latexTS_df_reg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting the mean, std, and percentiles of factor betas across all funds\n",
    "\n",
    "- To replicate Panel A of Table 2, for each fund i in month t, we run the following rolling time-series regression:\n",
    "$$\n",
    "\\text{ret}_{i,t+1-k} = \\alpha_{i,t} + \\beta_{\\text{MKT} i,t} \\times \\text{MKT}_{t+1-k} + \\beta_{\\text{HML} i,t} \\times \\text{HML}_{t+1-k} + \\beta_{\\text{SMB} i,t} \\times \\text{SMB}_{t+1-k} + \\beta_{\\text{MOM} i,t} \\times \\text{MOM}_{t+1-k} + \\beta_{\\text{CMA} i,t} \\times \\text{CMA}_{t+1-k} + \\beta_{\\text{RMW} i,t} \\times \\text{RMW}_{t+1-k} + \\beta_{\\text{flow} i,t} \\times \\text{flow}_{i,t+1-k} + \\epsilon_{i,t,t+1-k}\n",
    "$$\n",
    "where k = 1,2,...,60.\n",
    "\n",
    "- We require a fund should have 60 months of returns data and each rolling window contains 24 monthly observationswe need to run regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression(df):\n",
    "    beta = pd.DataFrame(columns = ['Mkt-RF', 'SMB', 'HML', 'MOM', 'CMA', 'RMW', 'flow'])\n",
    "\n",
    "    for fund, data in df.groupby('wficn'):\n",
    "        if len(data) >= 60: \n",
    "            for month in range(len(data)-59):\n",
    "                sample = data.iloc[month:month+60, :]\n",
    "                for rw in range(len(sample)-23):\n",
    "                    rolling_window = sample.iloc[rw:rw+24, :]\n",
    "                    X = rolling_window[['Mkt-RF', 'SMB', 'HML', 'MOM', 'CMA', 'RMW', 'flow']]\n",
    "                    y = rolling_window[['crsp_ret']]\n",
    "                    model = LinearRegression().fit(X, y)\n",
    "                    coef = pd.DataFrame((model.coef_).reshape(-1, 7), columns = ['Mkt-RF', 'SMB', 'HML', 'MOM', 'CMA', 'RMW', 'flow'])\n",
    "                    beta = pd.concat([beta, coef], axis=0)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_reg = df_reg.sample(frac=0.3, random_state=42)\n",
    "all_funds = regression(df_reg)\n",
    "panelA = all_funds.describe().loc[['mean', 'std']].append(all_funds.quantile(0.05)).append(all_funds.describe().loc[['25%', '50%', '75%']]).append(all_funds.quantile(0.95))\n",
    "panelA = panelA.rename(index={0.05: 'P5', '25%': 'P25', '50%': 'P50', '75%': 'P75', 0.95: 'P95'})\n",
    "panelA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting the mean factor betas by Lipper mutual fund classifications\n",
    "\n",
    "- To replicate Panel B of Table 2, we classify funds according to `lipper_class_name`, and then run the regressions again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_growth = df_reg[df_reg['lipper_class_name'].astype(str).str.contains('Growth', case=False, regex=True)]\n",
    "df_value = df_reg[df_reg['lipper_class_name'].astype(str).str.contains('Value', case=False, regex=True)]\n",
    "df_base = df_reg[df_reg['lipper_class_name'].astype(str).str.contains('Base', case=False, regex=True)]\n",
    "df_large_cap = df_reg[df_reg['lipper_class_name'].astype(str).str.contains('Large-Cap', case=False, regex=True)]\n",
    "df_mid_cap = df_reg[df_reg['lipper_class_name'].astype(str).str.contains('Mid-Cap', case=False, regex=True)]\n",
    "df_small_cap = df_reg[df_reg['lipper_class_name'].astype(str).str.contains('Small-Cap', case=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth = regression(df_growth)\n",
    "value = regression(df_value)\n",
    "base = regression(df_base)\n",
    "large_cap = regression(df_large_cap)\n",
    "mid_cap = regression(df_mid_cap)\n",
    "small_cap = regression(df_small_cap)\n",
    "panelB = pd.DataFrame({'All': all_funds.mean(), 'Growth': growth.mean(), 'Value': value.mean(), \n",
    "              'Large cap': large_cap.mean(), 'Medium cap': mid_cap.mean(), 'Small cap': small_cap.mean()}).T\n",
    "panelB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting the mean factor betas by index fund status\n",
    "- To replicate Panel C of Table 2, we classify funds according to index fund status.\n",
    "- `index_fund_flag` identifies if a fund is an index fund:\n",
    "- B = index-based fund\n",
    "- D = pure index fund\n",
    "- E = index fund enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = df_reg[df_reg['index_fund_flag'].astype(str).str.contains('D|B|E', case=False, regex=True)]\n",
    "df_enhanced = df_reg[df_reg['index_fund_flag'].astype(str).str.contains('E', case=False, regex=True)]\n",
    "df_base = df_reg[df_reg['index_fund_flag'].astype(str).str.contains('B', case=False, regex=True)]\n",
    "df_pure = df_reg[df_reg['index_fund_flag'].astype(str).str.contains('D', case=False, regex=True)]\n",
    "df_non_index = df_reg[~df_reg['index_fund_flag'].astype(str).str.contains('D|B|E', case=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = regression(df_index)\n",
    "enhanced = regression(df_enhanced)\n",
    "base = regression(df_base)\n",
    "pure = regression(df_pure)\n",
    "non_index = regression(df_non_index)\n",
    "panelC = pd.DataFrame({'All index funds': index.mean(), 'Enhanced': enhanced.mean(), 'Base': base.mean(), \n",
    "              'Pure': pure.mean(), 'All non-index funds': non_index.mean()}).T\n",
    "panelC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
